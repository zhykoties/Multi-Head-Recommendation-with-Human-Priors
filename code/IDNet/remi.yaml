model: REMI
# 2. REMI Specific Hyperparameters
# Lambda (λ) for Routing Regularization (RR). Paper sets this to 1e2.
lambda_rr: 100.0
# Beta (β) for Interest-aware Hard Negative mining (IHN).
# Paper searches {0.1, 1, 4, 10}. We start with 1.0.
beta_ihn: 1.0

# -------------------------------------------------
# 3. Architecture Alignment (ComiRec-SA Base)
# The paper builds REMI on ComiRec-SA, which applies multi-interest extraction
# directly on item/positional embeddings without deep sequential encoders.
# To replicate this, we must bypass the HSTU layers.
skip_hstu: False

hidden_act: 'silu'
enable_relative_attention_bias: True

total_iters: 30000
eval_interval: 3000

eval_pred_len: 1
pred_len: 1

split_mode: combine
medusa_lambda: 0.99
medusa_num_layers: 0
num_segment_head: 1
num_prior_head: 1
head_interaction: "multiplicative"
eval_num_cats: 1
interest_hidden_ratio: 0.5
attention_net_bias: False
num_interest: 4

tag_version: "v2"
outlier_user_metrics: "category"  # whether to compute metrics just for when the target items belong to some categories different from the context items